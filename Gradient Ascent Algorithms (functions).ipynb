{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Ascent_Algo(X, y, beta, alpha, numIterations): \n",
    "    # sample size \n",
    "    j=0;\n",
    "    N = len(X) \n",
    "    XTrans = X.transpose()\n",
    "    # create a vector to save all the likelihood values at each iteration \n",
    "    likelihood_values = np.zeros((numIterations,1)) \n",
    "    beta_values = np.zeros((numIterations+1,len(beta)))\n",
    "    beta_values[0,:]= beta\n",
    "    for i in range(0, numIterations): \n",
    "        # predicted values from the model \n",
    "        f_X = np.dot(X, beta)\n",
    "        # calculte the likelihood\n",
    "        diff = y - f_X\n",
    "        L = -(1/(2*N))*sum(np.square(diff))\n",
    "        # save all the likelihood values at each iteration \n",
    "        likelihood_values[i] = L\n",
    "        # calcualte the gradient using matrix representation\n",
    "        grad = (1/N)*np.matmul(XTrans,diff)\n",
    "        # update the parameters simulteneously with learning rate alpha\n",
    "        beta = beta+alpha*grad   \n",
    "        # save all the estimated parametes at each step \n",
    "        beta_values[i+1,:]= beta.transpose()\n",
    "    return beta, likelihood_values, beta_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Ascent_Algo_Stop(X, y, beta, alpha, numIterations, precision): \n",
    "    # sample size \n",
    "    j=0;\n",
    "    N = len(X) \n",
    "    XTrans = X.transpose()\n",
    "    # create a vector to save all the likelihood values at each iteration \n",
    "    likelihood_values = np.zeros((numIterations,1)) \n",
    "    beta_values = np.zeros((numIterations+1,len(beta)))\n",
    "    beta_values[0,:]= beta\n",
    "    grad_old=0\n",
    "    for i in range(0, numIterations): \n",
    "        # predicted values from the model \n",
    "        f_X = np.dot(X, beta)\n",
    "        # calculte the likelihood\n",
    "        diff = y - f_X\n",
    "        L = -(1/(2*N))*sum(np.square(diff))\n",
    "        # save all the likelihood values at each iteration \n",
    "        likelihood_values[i] = L\n",
    "\n",
    "        # calcualte the gradient using matrix representation\n",
    "        grad = (1/N)*np.matmul(XTrans,diff)\n",
    "        if (abs(sum(grad))<precision):\n",
    "            #print(sum(grad))\n",
    "            break\n",
    "        # update the parameters simulteneously with learning rate alpha\n",
    "        beta = beta+alpha*grad   \n",
    "        # save all the estimated parametes at each step \n",
    "        beta_values[i+1,:]= beta.transpose()\n",
    "        grad_old=grad\n",
    "    return beta, likelihood_values[:i+1], beta_values[:i+1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
