{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_test(predictors, response, data, test):\n",
    "    \n",
    "    neighbours=np.arange(1, 51)\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    for k in neighbours: \n",
    "        knn = KNeighborsRegressor(n_neighbors = k) \n",
    "        scores = cross_val_score(knn, data[predictors], data[response], cv=5, scoring = 'neg_mean_squared_error')\n",
    "        # taking the average of scores across 10 folds\n",
    "        cv_score = np.mean(scores)\n",
    "        # use the cv score for model selection\n",
    "        if cv_score >= best_score:\n",
    "            best_score = cv_score\n",
    "            best_knn = knn\n",
    "    \n",
    "    knn = best_knn\n",
    "    # train the selected model with the whole train set\n",
    "    knn.fit(data[predictors], data[response])\n",
    "    # Predict the test data with the selected and re-estimated model\n",
    "    predictions = knn.predict(test[predictors])\n",
    "    test_rmse = np.sqrt(mean_squared_error(test[response], predictions))\n",
    "    cv_rmse= np.sqrt(-best_score)\n",
    "    print('Chosen K: {}'.format(knn.n_neighbors))\n",
    "    \n",
    "    return test_rmse, cv_rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_test_mahalanobis(predictors, response, data, test):\n",
    "    \n",
    "    neighbours=np.arange(1, 51)\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    for k in neighbours: \n",
    "        knn = KNeighborsRegressor(n_neighbors = k, metric='mahalanobis', metric_params={'V': data[predictors].cov()}) \n",
    "        scores = cross_val_score(knn, data[predictors], data[response], cv=5, scoring = 'neg_mean_squared_error')\n",
    "        # taking the average of scores across 10 folds\n",
    "        cv_score = np.mean(scores)\n",
    "        # use the cv score for model selection\n",
    "        if cv_score >= best_score:\n",
    "            best_score = cv_score\n",
    "            best_knn = knn\n",
    "    \n",
    "    knn = best_knn\n",
    "    # train the selected model with the whole train set\n",
    "    knn.fit(data[predictors], data[response])\n",
    "    # Predict the test data with the selected and re-estimated model\n",
    "    predictions = knn.predict(test[predictors])\n",
    "    test_rmse = np.sqrt(mean_squared_error(test[response], predictions))\n",
    "    cv_rmse= np.sqrt(-best_score)\n",
    "    #print('Chosen K: {}'.format(knn.n_neighbors))\n",
    "    \n",
    "    return test_rmse, cv_rmse, knn.n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_test_standardised(predictors, response, data, test):\n",
    "    \n",
    "    neighbours=np.arange(1, 31)\n",
    "    best_score = -np.inf\n",
    "    y_train=data[response]\n",
    "    y_test=test[response]\n",
    "    mu=data[predictors].mean()\n",
    "    sigma=data[predictors].std()\n",
    "    standardised_knn_train=(data[predictors]-mu)/sigma\n",
    "    standardised_knn_test=(test[predictors]-mu)/sigma\n",
    "    best_score=-100\n",
    "    for k in neighbours: \n",
    "        knn = KNeighborsRegressor(n_neighbors = k) \n",
    "        scores = cross_val_score(knn, standardised_knn_train, y_train, cv=5, scoring = 'neg_mean_squared_error')\n",
    "        # taking the average of scores across 5 folds\n",
    "        cv_score = np.mean(scores)\n",
    "        # use the cv score for model selection\n",
    "        if cv_score >= best_score:\n",
    "            best_score = cv_score\n",
    "            best_knn = knn\n",
    "    \n",
    "    knn = best_knn\n",
    "    # train the selected model with the whole train set\n",
    "    knn.fit(standardised_knn_train[predictors], y_train)\n",
    "    # Predict the test data with the selected and re-estimated model\n",
    "    predictions = knn.predict(standardised_knn_test[predictors])\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    cv_rmse= np.sqrt(-best_score)\n",
    "    #print('Chosen K: {}'.format(knn.n_neighbors))\n",
    "    \n",
    "    return test_rmse, cv_rmse, knn.n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Ascent_Algo(X, y, beta, alpha, numIterations): \n",
    "    # sample size \n",
    "    j=0;\n",
    "    N = len(X) \n",
    "    XTrans = X.transpose()\n",
    "    # create a vector to save all the likelihood values at each iteration \n",
    "    likelihood_values = np.zeros((numIterations,1)) \n",
    "    beta_values = np.zeros((numIterations+1,len(beta)))\n",
    "    beta_values[0,:]= beta\n",
    "    for i in range(0, numIterations): \n",
    "        # predicted values from the model \n",
    "        f_X = np.dot(X, beta)\n",
    "        # calculte the likelihood\n",
    "        diff = y - f_X\n",
    "        L = -(1/(2*N))*sum(np.square(diff))\n",
    "        # save all the likelihood values at each iteration \n",
    "        likelihood_values[i] = L\n",
    "        # calcualte the gradient using matrix representation\n",
    "        grad = (1/N)*np.matmul(XTrans,diff)\n",
    "        # update the parameters simulteneously with learning rate alpha\n",
    "        beta = beta+alpha*grad   \n",
    "        # save all the estimated parametes at each step \n",
    "        beta_values[i+1,:]= beta.transpose()\n",
    "    return beta, likelihood_values, beta_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Ascent_Algo_Stop(X, y, beta, alpha, numIterations, precision): \n",
    "    # sample size \n",
    "    j=0;\n",
    "    N = len(X) \n",
    "    XTrans = X.transpose()\n",
    "    # create a vector to save all the likelihood values at each iteration \n",
    "    likelihood_values = np.zeros((numIterations,1)) \n",
    "    beta_values = np.zeros((numIterations+1,len(beta)))\n",
    "    beta_values[0,:]= beta\n",
    "    grad_old=0\n",
    "    for i in range(0, numIterations): \n",
    "        # predicted values from the model \n",
    "        f_X = np.dot(X, beta)\n",
    "        # calculte the likelihood\n",
    "        diff = y - f_X\n",
    "        L = -(1/(2*N))*sum(np.square(diff))\n",
    "        # save all the likelihood values at each iteration \n",
    "        likelihood_values[i] = L\n",
    "\n",
    "        # calcualte the gradient using matrix representation\n",
    "        grad = (1/N)*np.matmul(XTrans,diff)\n",
    "        if (abs(sum(grad))<precision):\n",
    "            #print(sum(grad))\n",
    "            break\n",
    "        # update the parameters simulteneously with learning rate alpha\n",
    "        beta = beta+alpha*grad   \n",
    "        # save all the estimated parametes at each step \n",
    "        beta_values[i+1,:]= beta.transpose()\n",
    "        grad_old=grad\n",
    "    return beta, likelihood_values[:i+1], beta_values[:i+1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
